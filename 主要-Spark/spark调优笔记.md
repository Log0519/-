# 一、spark调优笔记
@[toc]
cache中可以发现
rdd尽量kryo序列化，sparksql不需要kryo，内置自己实现。
广播join，hive是mapjoin

## 1、过滤少数导致倾斜的key

## 2、提高shuffle操作算子的并行度(增加 shuffle read task)

## 3、RDD建议使用reduceBuKey或者aggregateByKey替代groupByKey

## 4、两阶段聚合：sql本身map端自动预聚合，还可以手动二次聚合，也是用key打乱倾斜的key值，然后去随机数

## 5、广播join(大小表)，SMBjoin(大大表，分桶、排序、合并)

## 6、拆分key打散大表添加随机前缀，扩容小表
对小表每条数据三倍扩容，添加三种前缀，可以添加在case样例类中，单独用一个字段保存随机数，用来关联，就不用去随机数

## 7、CombineHiveInputformat
Hive里面CombineHiveInputformat会把多个小文件读取到一个map任务里面去

# 二、Spark数据倾斜处理
是指在进行数据处理的过程中，某些Key的数据比其他Key的数据更多，从而导致Spark任务运行时间不均衡。以下是一些常见的Spark

## 1. Shuffle前置：
在Join、GroupBy等需要Shuffle操作的之前，对数据进行预处理，将Key重新分配到不同的分区中。这种方式可以使得数据分布更加均匀，减少数据倾斜的发生。

## 2. 数据重分区（Repartition）：
通过增大或减小分区数量，调整数据分布以达到负载均衡的效果。使用repartition来增加分区数，让每个分区的数据量尽可能平均。但是要注意不要设置过多的分区，因为较小的分区会导致性能下降。

## 3. 键值对重组：
将数据按照Key分组之后，在每个分组中再次按照另一个Key进行分区，这样可以使得每个Key的数据被均匀地分配到不同的分区中。

## 4. 聚合合并（Aggregation）：
在执行聚合操作之前，先对数据进行合并，减少参与聚合的数据量，从而降低了计算时间和内存消耗。

## 5. Bloom Filter：
使用Bloom Filter技术，将Key映射成位数组中的位置，并标记出现的位置，查询时只需检查位数组即可知道是否存在该Key，从而避免了全局扫描。

## 6. 随机Key/Value：
在执行某些操作时，将原始Key/Value转换为随机的Key/Value，这样可以避免出现数据倾斜的问题。但是需要注意，这种方式有可能会导致结果出现偏差。

## 7. 调整资源：
如果某个Task处理时间过长，可以考虑增加该Task的资源配置，如executor内存、CPU核数等。这样可以确保该Task的运行速度与其他Task相当，从而达到负载均衡的效果。

需要注意的是，不同的数据处理场景可能需要采用不同的解决方案，具体处理方法需要根据实际情况进行选取。

# 三、为什么扩容小表可以减少join次数


在数据库中，当我们需要将两个或多个表的行连接起来时，通常会使用join操作。如果一个表很小，而另一个表非常大，则该操作可能会变得非常慢，因为必须扫描大表的每一行以找到匹配的行。

通过扩容小表，我们可以增加该表中的行数，使其接近另一个较大的表。这样，执行Join操作时，需要扫描的行数就减少了。因为扫描的行数更少，所以查询的执行速度也会更快，并且可以减少Join操作的次数。

需要注意的是，扩容小表并不总是可以使Join操作更快。如果小表本来就已经足够大，那么再次扩展它可能不会带来任何好处。此外，还需要考虑内存和磁盘空间的限制，因为扩容小表可能会占用更多的资源。

# 四、给出spark数据倾斜的所有优化方案

## 1. 数据分区:
在数据读取阶段,通过适当的分区策略,使数据分布更加均匀。例如:哈希分区、范围分区等。
## 2. 采样:
通过采样的方式减少数据规模,避免数据倾斜。
## 3. 过滤:
过滤掉不需要处理的大量数据,从而减少数据量,减轻倾斜。
## 4. 使用broadcast变量:
将较小的集合广播到各个executor,从而避免数据倾斜。
## 5. 重新分区:
在shuffle阶段,可以通过HashPartitioner等分区策略重新分区,达到数据均衡的目的。
## 6. 调整并行度:
增大或减小并行度,使数据分布更加均匀。
## 7. 使用数据本地化:
在任务调度阶段,将数据分布较均衡的partition分配给同一个executor,从而减少shuffle带来的网络传输。
## 8. 自定义Partitioner:
实现自己的Partitioner,达到更好的分区效果。
## 9. 优化shuffle:
通过调整shuffle中的并行数、批处理数据大小、索引等方式优化shuffle过程,减少数据倾斜。
## 10. 其他:
使用数据压缩,在内存中缓存数据等方式也可以优化Spark程序,减少数据倾斜。

# 五、打散大表，扩容小表的好处
打散大表可以把大表拆分成多个小表,每个小表的数据量相对均衡,这样在查询的时候会访问多个小表,而不是访问一个巨大的表,减少单表扫描的数据量,提高查询效率。扩容小表可以让小表变得更大一些,这样在查询的时候访问的表数会减少,减少join操作的次数,提高查询效率。

# 六、Map端优化

## spark读取小文件

1、spark.sql.files.maxPartitionBytes调整每个分区最大的字节数，一个分区可以容纳这么多的数据，小文件可以读到同一个分区

2、spark.files.openCostInBytes打开一个文件的开销，小于这个值就会被合并到同一个分区**是错的**,应该是计算：N个总文件大小+N×openCostInBytes<=maxPartitionBytes，作为判断依据,一般这个参数小文件过多的时候设置接近小文件的大小

3、调大ShuffleWrite溢写时的输出流缓冲，可以提高溢写效率
